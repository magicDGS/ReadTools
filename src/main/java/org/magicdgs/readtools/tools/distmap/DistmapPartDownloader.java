/*
 * The MIT License (MIT)
 *
 * Copyright (c) 2017 Daniel Gomez-Sanchez
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

package org.magicdgs.readtools.tools.distmap;

import org.magicdgs.readtools.cmd.argumentcollections.RTOutputArgumentCollection;

import avro.shaded.com.google.common.collect.Lists;
import htsjdk.samtools.SAMFileHeader;
import htsjdk.samtools.SAMProgramRecord;
import htsjdk.samtools.SamReaderFactory;
import htsjdk.samtools.ValidationStringency;
import htsjdk.samtools.util.IOUtil;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.broadinstitute.barclay.argparser.Advanced;
import org.broadinstitute.barclay.argparser.Argument;
import org.broadinstitute.barclay.argparser.ArgumentCollection;
import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;
import org.broadinstitute.hellbender.engine.GATKTool;
import org.broadinstitute.hellbender.engine.ProgressMeter;
import org.broadinstitute.hellbender.engine.ReadsDataSource;
import org.broadinstitute.hellbender.exceptions.GATKException;
import org.broadinstitute.hellbender.utils.Utils;
import org.broadinstitute.hellbender.utils.io.IOUtils;
import org.broadinstitute.hellbender.utils.read.GATKRead;
import org.broadinstitute.hellbender.utils.read.GATKReadWriter;
import org.broadinstitute.hellbender.utils.read.ReadConstants;

import java.io.File;
import java.io.IOException;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;
import java.util.function.Function;
import java.util.stream.Collectors;

/**
 * @author Daniel Gomez-Sanchez (magicDGS)
 */
final class DistmapPartDownloader {

    protected final Logger logger = LogManager.getLogger(this.getClass());

    // For the progress meter in the GATKTool
    @Argument(fullName = GATKTool.SECONDS_BETWEEN_PROGRESS_UPDATES_NAME, shortName = GATKTool.SECONDS_BETWEEN_PROGRESS_UPDATES_NAME, doc = "Output traversal statistics every time this many seconds elapse.", optional = true, common = true)
    private double secondsBetweenProgressUpdates = ProgressMeter.DEFAULT_SECONDS_BETWEEN_UPDATES;

    @Argument(fullName = StandardArgumentDefinitions.REFERENCE_LONG_NAME, shortName = StandardArgumentDefinitions.REFERENCE_SHORT_NAME, doc = "Reference sequence file. Required for CRAM input/output.", optional = true, common = true)
    private File referenceFile = null;

    @ArgumentCollection
    private RTOutputArgumentCollection outputArgumentCollection =
            RTOutputArgumentCollection.defaultOutput();

    @Argument(fullName = "SORT_ORDER", shortName = StandardArgumentDefinitions.SORT_ORDER_SHORT_NAME, doc = "Sort order of output file", optional = true, common = true)
    private SAMFileHeader.SortOrder sortOrder = SAMFileHeader.SortOrder.coordinate;

    @Advanced
    @Argument(fullName = "partBatches", doc = "Number of parts to download and merge at the same time. Reduce this number if you have memory errors.", optional = true, minValue = 1)
    private int numberOfBatches = 100;

    @Advanced
    @Argument(fullName = "noDropProgramGroups", doc = "Do not drop the PG generated by running Distmap. This include the command line for every Map-Reduce task.", optional = true)
    private boolean noDropProgramGroups = false;

    @Argument(fullName = StandardArgumentDefinitions.READ_VALIDATION_STRINGENCY_LONG_NAME, shortName = StandardArgumentDefinitions.READ_VALIDATION_STRINGENCY_SHORT_NAME,
            doc = "Validation stringency for all SAM/BAM/CRAM files read by this program. "
                    + "The default stringency value SILENT can improve performance when processing "
                    + "a BAM file in which variable-length data (read, qualities, tags) do not otherwise need to be decoded.",
            common = true, optional = true)
    private ValidationStringency readValidationStringency =
            ReadConstants.DEFAULT_READ_VALIDATION_STRINGENCY;

    // SamReaderFactory constructed on demand with the parameters
    private SamReaderFactory factory = null;

    private SamReaderFactory getSamReaderFactory() {
        if (factory == null) {
            factory = SamReaderFactory.makeDefault()
                    .referenceSequence(referenceFile)
                    .validationStringency(readValidationStringency);
        }
        return factory;
    }

    public void downloadParts(final List<Path> partFiles, final Function<SAMFileHeader, SAMProgramRecord> programRecord) {
        Utils.nonEmpty(partFiles);
        outputArgumentCollection.validateUserOutput();

        // for the final merging
        final ReadsDataSource toMerge;
        final boolean presorted;

        if(partFiles.size() <= numberOfBatches) {
            // logging the process and start the progress meter
            logger.info(
                    "Only {} parts found: download will be performed at the same time as merging",
                    partFiles::size);
            toMerge = new ReadsDataSource(partFiles, getSamReaderFactory());
            presorted = isPresorted();
        } else {
            toMerge = downloadBatchesAndPreSort(partFiles);
            presorted = true;
        }

        final SAMFileHeader header = setHeaderOptions(toMerge.getHeader());

        // initialize the progress meter
        logger.info("Merging output");
        final ProgressMeter mergingProgress = new ProgressMeter(secondsBetweenProgressUpdates);
        mergingProgress.start();

        writeReads(toMerge,
                outputArgumentCollection.outputWriter(header, () -> programRecord.apply(header),
                        presorted, referenceFile),
                mergingProgress);

        // logging the end
        mergingProgress.stop();
        logger.debug("Finished download and merging.", partFiles.size());
    }

    private boolean isPresorted() {
        // TODO: this should also include the header to check if they are sorted in the same order
        // TODO: nevertheless, GATK ReadsDataSource returns a merged header with coordinate sort order
        // TODO: and it is impossible to distinguish when it is pre-sorted
        return SAMFileHeader.SortOrder.unsorted == sortOrder;
    }

    private SAMFileHeader setHeaderOptions(final SAMFileHeader header) {
        header.setSortOrder(sortOrder);
        if (!noDropProgramGroups) {
            header.setProgramRecords(new ArrayList<>());
        }
        return header;
    }


    /**
     * Write the reads contained in the source into the writer.
     *
     * Note: the writer is closed before returning.
     */
    private void writeReads(final ReadsDataSource reads, final GATKReadWriter writer,
            final ProgressMeter progressMeter) {
        for (final GATKRead read : reads) {
            writer.addRead(read);
            progressMeter.update(read);
        }
        try {
            writer.close();
        } catch (IOException e) {
            throw new GATKException("Unable to close writer");
        }
    }

    private ReadsDataSource downloadBatchesAndPreSort(final List<Path> partFiles) {
        // partition the files into batches
        final Map<Path, ReadsDataSource> batches =
                divideIntoBatches(partFiles, numberOfBatches);

        // logging the downloading process
        logger.info("Downloading parts in {} batches.", batches::size);
        final ProgressMeter downloadProgress = new ProgressMeter(secondsBetweenProgressUpdates);
        downloadProgress.start();

        // download in batches
        batches.entrySet().forEach(entry -> {
            final String batchName = entry.getKey().toUri().toString();
            final SAMFileHeader header = setHeaderOptions(entry.getValue().getHeader());
            logger.debug("Downloading batch: {}.", () -> batchName);
            writeReads(entry.getValue(),
                    // create based on the batch name, which is BAM and does not require the reference
                    outputArgumentCollection.getWriterFactory()
                            // do not create indexes for the files that are batches
                            .setCreateIndex(false)
                            // overwrite previous batches (this should never happen, but it is a temp folder)
                            .setForceOverwrite(true)
                            .createSAMWriter(batchName, header, isPresorted()),
                    downloadProgress);
        });
        downloadProgress.stop();
        logger.info("Finished download.");
        return new ReadsDataSource(new ArrayList<>(batches.keySet()), getSamReaderFactory());
    }

    private Map<Path, ReadsDataSource> divideIntoBatches(final List<Path> partFiles,
            final int numberOfBatches) {
        // partition the files into batches
        final List<List<Path>> batches = Lists.partition(partFiles, numberOfBatches);
        final Map<Path, ReadsDataSource> toReturn = new LinkedHashMap<>(batches.size());

        // creates a temp file for each in a common temp folder
        final File tempDir = IOUtil.createTempDir(this.toString(), ".batches");
        int i = 0;
        for (final List<Path> parts : batches) {
            // create a temp file and store it in the temp parts
            final Path tempFile =
                    IOUtils.getPath(new File(tempDir, "batch-" + i++ + ".bam").getAbsolutePath());
            logger.debug("Batch file {} will contain {} parts: {}",
                    () -> tempFile.toUri().toString(),
                    () -> parts.size(),
                    () -> parts.stream().map(p -> p.toUri().toString())
                            .collect(Collectors.toList()));
            toReturn.put(tempFile, new ReadsDataSource(parts, getSamReaderFactory()));
        }

        return toReturn;
    }

}
